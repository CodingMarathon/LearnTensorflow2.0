{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1,低阶API示范\n",
    "\n",
    "下面的范例使用TensorFlow的低阶API实现线性回归模型。\n",
    "\n",
    "低阶API主要包括张量操作，计算图和自动微分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    ts = tf.timestamp()\n",
    "    today_ts = ts%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "    \n",
    "    def timeformat(m):\n",
    "        # 对于个位数的数字，在前面添加0\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "    \n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n",
    "                timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8,end = \"\")\n",
    "    tf.print(timestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#样本数量\n",
    "n = 400\n",
    "\n",
    "# 生成测试用数据集\n",
    "X = tf.random.uniform([n,2],minval=-10,maxval=10) \n",
    "w0 = tf.constant([[2.0],[-1.0]])\n",
    "b0 = tf.constant(3.0)\n",
    "Y = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================16:12:30\n",
      "epoch = 1000  loss = 2.51871967\n",
      "w = [[1.98677838]\n",
      " [-1.00795388]]\n",
      "b = 1.93567574\n",
      "\n",
      "================================================================================16:12:32\n",
      "epoch = 2000  loss = 1.97233057\n",
      "w = [[1.98137867]\n",
      " [-1.01008439]]\n",
      "b = 2.64583397\n",
      "\n",
      "================================================================================16:12:34\n",
      "epoch = 3000  loss = 1.89814222\n",
      "w = [[1.97938931]\n",
      " [-1.01086855]]\n",
      "b = 2.90751576\n",
      "\n",
      "================================================================================16:12:36\n",
      "epoch = 4000  loss = 1.8880688\n",
      "w = [[1.9786551]\n",
      " [-1.01115859]]\n",
      "b = 3.00394082\n",
      "\n",
      "================================================================================16:12:38\n",
      "epoch = 5000  loss = 1.88670135\n",
      "w = [[1.97838593]\n",
      " [-1.01126552]]\n",
      "b = 3.03947139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用动态图调试\n",
    "\n",
    "w = tf.Variable(tf.random.normal(w0.shape))\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "def train(epoches):\n",
    "    for epoch in tf.range(1,epoches+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #正向传播求损失\n",
    "            Y_hat = X@w + b\n",
    "            # 均方损失\n",
    "            # squeeze是转换成标量\n",
    "            loss = tf.squeeze(tf.transpose(Y-Y_hat)@(Y-Y_hat))/(2.0*n)   \n",
    "\n",
    "        # 反向传播求梯度\n",
    "        dloss_dw,dloss_db = tape.gradient(loss,[w,b])\n",
    "        # 梯度下降法更新参数\n",
    "        w.assign(w - 0.001*dloss_dw)\n",
    "        b.assign(b - 0.001*dloss_db)\n",
    "        if epoch%1000 == 0:\n",
    "            printbar()\n",
    "            tf.print(\"epoch =\",epoch,\" loss =\",loss,)\n",
    "            tf.print(\"w =\",w)\n",
    "            tf.print(\"b =\",b)\n",
    "            tf.print(\"\")\n",
    "            \n",
    "train(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================16:13:44\n",
      "epoch = 1000  loss = 2.52051115\n",
      "w = [[1.98679066]\n",
      " [-1.00794923]]\n",
      "b = 1.93408406\n",
      "\n",
      "================================================================================16:13:44\n",
      "epoch = 2000  loss = 1.972574\n",
      "w = [[1.98138297]\n",
      " [-1.0100826]]\n",
      "b = 2.64524698\n",
      "\n",
      "================================================================================16:13:45\n",
      "epoch = 3000  loss = 1.89817536\n",
      "w = [[1.97939098]\n",
      " [-1.01086783]]\n",
      "b = 2.90729809\n",
      "\n",
      "================================================================================16:13:45\n",
      "epoch = 4000  loss = 1.88807368\n",
      "w = [[1.9786557]\n",
      " [-1.01115835]]\n",
      "b = 3.00385976\n",
      "\n",
      "================================================================================16:13:45\n",
      "epoch = 5000  loss = 1.88670206\n",
      "w = [[1.97838616]\n",
      " [-1.01126552]]\n",
      "b = 3.03944039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##使用autograph机制转换成静态图加速\n",
    "\n",
    "w = tf.Variable(tf.random.normal(w0.shape))\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "@tf.function\n",
    "def train(epoches):\n",
    "    for epoch in tf.range(1,epoches+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #正向传播求损失\n",
    "            Y_hat = X@w + b\n",
    "            loss = tf.squeeze(tf.transpose(Y-Y_hat)@(Y-Y_hat))/(2.0*n)   \n",
    "\n",
    "        # 反向传播求梯度\n",
    "        dloss_dw,dloss_db = tape.gradient(loss,[w,b])\n",
    "        # 梯度下降法更新参数\n",
    "        w.assign(w - 0.001*dloss_dw)\n",
    "        b.assign(b - 0.001*dloss_db)\n",
    "        if epoch%1000 == 0:\n",
    "            printbar()\n",
    "            tf.print(\"epoch =\",epoch,\" loss =\",loss,)\n",
    "            tf.print(\"w =\",w)\n",
    "            tf.print(\"b =\",b)\n",
    "            tf.print(\"\")\n",
    "train(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
