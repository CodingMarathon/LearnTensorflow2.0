{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_for_line_given_points(b, w, points):\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        totalError += (points[i, 1] - (w * points[i, 0] + b)) ** 2\n",
    "    return totalError / float(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(b_current, w_current, points, learningRate):\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        b_gradient += (2/N) * ((w_current * points[i, 0] + b_current) - points[i, 1])\n",
    "        w_gradient += (2/N) * ((w_current * points[i, 0] + b_current) - points[i, 1]) * points[i, 0]\n",
    "    new_b = b_current - (learningRate * b_gradient)\n",
    "    new_w = w_current - (learningRate * w_gradient)\n",
    "    return [new_b, new_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner(points, starting_b, starting_w, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    w = starting_w\n",
    "    for i in range(num_iterations):\n",
    "        b, w = step_gradient(b, w, np.array(points), learning_rate)\n",
    "    return [b, w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "x_data = np.random.uniform(size= [100],low=-1, high=1 )\n",
    "y_data = x_data * 0.25 + 0.6 + np.random.normal(scale=0.002, size=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.stack([x_data, y_data], axis=1)\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting gradient descent at b = 0, w= 0, error=0.38243412235094676\n",
      "After 1000 Iterations b = 0.5189978449461509 w = 0.12772574574109527, error = 0.011893269607985004\n"
     ]
    }
   ],
   "source": [
    "starting_b = 0\n",
    "starting_w = 0\n",
    "learning_rate = 0.001\n",
    "num_iterations = 1000\n",
    "print(\"starting gradient descent at b = {}, w= {}, error={}\".format(\n",
    "    starting_b,\n",
    "    starting_w,\n",
    "    compute_error_for_line_given_points(starting_b, starting_w, points)))\n",
    "b, w = gradient_descent_runner(points, starting_b, starting_w, learning_rate, num_iterations)\n",
    "print('After {} Iterations b = {} w = {}, error = {}'.format(\n",
    "    num_iterations,\n",
    "    b,\n",
    "    w,\n",
    "    compute_error_for_line_given_points(b, w, points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting gradient descent at b = 0, w= 0, error=0.38243412235094676\n",
      "Epoch: 0\n",
      "After 1000 Iterations b = 0.5189978449461509 w = 0.12772574574109527, error = 0.011893269607985004\n",
      "Epoch: 1\n",
      "After 1000 Iterations b = 0.5890097528603323 w = 0.19009229210935005, error = 0.0014055047648192515\n",
      "Epoch: 2\n",
      "After 1000 Iterations b = 0.5984236237020641 w = 0.22066932772238668, error = 0.00031521631688654706\n",
      "Epoch: 3\n",
      "After 1000 Iterations b = 0.5996743709551847 w = 0.23567751599161627, error = 7.85657041563115e-05\n",
      "Epoch: 4\n",
      "After 1000 Iterations b = 0.5998331240337204 w = 0.24304630103965708, error = 2.198266550125045e-05\n",
      "Epoch: 5\n",
      "After 1000 Iterations b = 0.5998495681575994 w = 0.24666456776227963, error = 8.347961734747004e-06\n",
      "Epoch: 6\n",
      "After 1000 Iterations b = 0.5998493350913593 w = 0.2484412733385551, error = 5.060488883722297e-06\n",
      "Epoch: 7\n",
      "After 1000 Iterations b = 0.5998480985590101 w = 0.24931370849460477, error = 4.267808527182899e-06\n",
      "Epoch: 8\n",
      "After 1000 Iterations b = 0.5998473398160958 w = 0.2497421106248448, error = 4.076675609749847e-06\n",
      "Epoch: 9\n",
      "After 1000 Iterations b = 0.5998469467719603 w = 0.24995247408120114, error = 4.030589187661355e-06\n",
      "Epoch: 10\n",
      "After 1000 Iterations b = 0.5998467510060547 w = 0.25005577139602314, error = 4.019476720114479e-06\n",
      "Epoch: 11\n",
      "After 1000 Iterations b = 0.5998466545033388 w = 0.2501064947290047, error = 4.016797255544103e-06\n",
      "Epoch: 12\n",
      "After 1000 Iterations b = 0.5998466070660049 w = 0.2501314020224742, error = 4.016151176682268e-06\n",
      "Epoch: 13\n",
      "After 1000 Iterations b = 0.5998465837654638 w = 0.25014363255294797, error = 4.015995392612484e-06\n",
      "Epoch: 14\n",
      "After 1000 Iterations b = 0.5998465723229971 w = 0.2501496382587038, error = 4.015957829587541e-06\n",
      "Epoch: 15\n",
      "After 1000 Iterations b = 0.5998465667041392 w = 0.25015258731326195, error = 4.015948772301712e-06\n",
      "Epoch: 16\n",
      "After 1000 Iterations b = 0.5998465639450256 w = 0.250154035423299, error = 4.015946588387423e-06\n",
      "Epoch: 17\n",
      "After 1000 Iterations b = 0.5998465625901823 w = 0.25015474650634, error = 4.015946061796866e-06\n",
      "Epoch: 18\n",
      "After 1000 Iterations b = 0.599846561924899 w = 0.25015509567807176, error = 4.015945934824093e-06\n",
      "Epoch: 19\n",
      "After 1000 Iterations b = 0.5998465615982148 w = 0.2501552671361038, error = 4.015945904208113e-06\n",
      "Epoch: 20\n",
      "After 1000 Iterations b = 0.5998465614378004 w = 0.2501553513292214, error = 4.015945896825917e-06\n",
      "Epoch: 21\n",
      "After 1000 Iterations b = 0.5998465613590294 w = 0.2501553926715889, error = 4.01594589504591e-06\n",
      "Epoch: 22\n",
      "After 1000 Iterations b = 0.5998465613203496 w = 0.2501554129724332, error = 4.015945894616725e-06\n",
      "Epoch: 23\n",
      "After 1000 Iterations b = 0.5998465613013562 w = 0.25015542294100335, error = 4.01594589451318e-06\n",
      "Epoch: 24\n",
      "After 1000 Iterations b = 0.59984656129203 w = 0.2501554278359912, error = 4.015945894488267e-06\n",
      "Epoch: 25\n",
      "After 1000 Iterations b = 0.5998465612874502 w = 0.2501554302396363, error = 4.0159458944822216e-06\n",
      "Epoch: 26\n",
      "After 1000 Iterations b = 0.5998465612852022 w = 0.250155431419927, error = 4.015945894480787e-06\n",
      "Epoch: 27\n",
      "After 1000 Iterations b = 0.5998465612840987 w = 0.2501554319994999, error = 4.0159458944804386e-06\n",
      "Epoch: 28\n",
      "After 1000 Iterations b = 0.5998465612835568 w = 0.2501554322840945, error = 4.015945894480354e-06\n",
      "Epoch: 29\n",
      "After 1000 Iterations b = 0.5998465612832905 w = 0.250155432423842, error = 4.015945894480336e-06\n",
      "Epoch: 30\n",
      "After 1000 Iterations b = 0.5998465612831689 w = 0.25015543249246386, error = 4.015945894480301e-06\n",
      "Epoch: 31\n",
      "After 1000 Iterations b = 0.5998465612830991 w = 0.25015543252616046, error = 4.015945894480322e-06\n",
      "Epoch: 32\n",
      "After 1000 Iterations b = 0.5998465612830788 w = 0.25015543254270717, error = 4.015945894480347e-06\n",
      "Epoch: 33\n",
      "After 1000 Iterations b = 0.5998465612830688 w = 0.2501554325508319, error = 4.015945894480315e-06\n",
      "Epoch: 34\n",
      "After 1000 Iterations b = 0.5998465612830639 w = 0.2501554325548217, error = 4.01594589448032e-06\n",
      "Epoch: 35\n",
      "After 1000 Iterations b = 0.5998465612830615 w = 0.2501554325567805, error = 4.015945894480316e-06\n",
      "Epoch: 36\n",
      "After 1000 Iterations b = 0.5998465612830602 w = 0.2501554325577422, error = 4.015945894480317e-06\n",
      "Epoch: 37\n",
      "After 1000 Iterations b = 0.5998465612830597 w = 0.25015543255821415, error = 4.015945894480325e-06\n",
      "Epoch: 38\n",
      "After 1000 Iterations b = 0.5998465612830594 w = 0.25015543255844513, error = 4.0159458944803335e-06\n",
      "Epoch: 39\n",
      "After 1000 Iterations b = 0.5998465612830592 w = 0.2501554325585601, error = 4.015945894480304e-06\n",
      "Epoch: 40\n",
      "After 1000 Iterations b = 0.5998465612830592 w = 0.2501554325586156, error = 4.015945894480318e-06\n",
      "Epoch: 41\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 42\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 43\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 44\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 45\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 46\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 47\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 48\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n",
      "Epoch: 49\n",
      "After 1000 Iterations b = 0.5998465612830591 w = 0.2501554325586318, error = 4.015945894480328e-06\n"
     ]
    }
   ],
   "source": [
    "starting_b = 0\n",
    "starting_w = 0\n",
    "learning_rate = 0.001\n",
    "num_iterations = 1000\n",
    "print(\"starting gradient descent at b = {}, w= {}, error={}\".format(\n",
    "    starting_b,\n",
    "    starting_w,\n",
    "    compute_error_for_line_given_points(starting_b, starting_w, points)))\n",
    "epoch = 50\n",
    "b = starting_b\n",
    "w = starting_w\n",
    "for i in range(epoch):\n",
    "    print('Epoch: {}'.format(i))\n",
    "    b, w = gradient_descent_runner(points, b, w, learning_rate, num_iterations)\n",
    "    print('After {} Iterations b = {} w = {}, error = {}'.format(\n",
    "        num_iterations,\n",
    "        b,\n",
    "        w,\n",
    "        compute_error_for_line_given_points(b, w, points)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
